{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import sqrtm\n",
    "#from skimage.transform import resize\n",
    "import cv2\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from keras.layers import Activation, Dense, Input, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Reshape, Concatenate, Lambda, Layer\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_squared_error, binary_crossentropy\n",
    "from keras import metrics\n",
    "from keras.applications.inception_v3 import preprocess_input, InceptionV3\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants\n",
    "OLD_IMAGE_DIMS = (218, 178, 3)\n",
    "NEW_IMAGE_DIMS = (64, 64, 3)\n",
    "CROP_IMAGE_DIMS = (25, 45, 153, 173)\n",
    "BATCH_SIZE = 128 # Hva er dette?\n",
    "N = 6\n",
    "NUM_ATTRIBUTES = 40\n",
    "NUM_BATCHES = 10\n",
    "LATENT_DIM = 64\n",
    "TOT_IMAGES = 202599\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants needed to run in Google Colab\n",
    "PATH = './'\n",
    "IMAGES = 'img_align_celeba/'\n",
    "ATTRIBUTES = 'list_attr_celeba.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABEq0lEQVR4nO29a5RkV3Um+J248Y7IzMjMysp6q6okoQegB6gBIaB5GCxj2cyyaQ0YprFb3bJpzwz29KwGPNMN7hlmZDeN5V6rm7bMQxoaG4SNkSzTgJBFg0HWC/QovaWSRFWpqrIq3494x5kfGXX3t3dmREWpqqIKx/nWqlXn5jn33HPPvSfu3mfv/W3nvUdAQMA/fCTO9AACAgL6g7DYAwIGBGGxBwQMCMJiDwgYEITFHhAwIAiLPSBgQHBSi905d7Vz7inn3LPOuY+dqkEFBASceriXa2d3zkUAngbwTgD7AdwP4P3e+8dP3fACAgJOFZInce7rADzrvd8LAM65rwB4D4COi31sfNxv27a9faR/ZJwqO+hKc7xuD92xfg8neBJdkH8kEwndkOvsj+ni0mJcnpmeUXUrK+X1zzP332p5qtJ1fJxIiODW5VbWjJHbtlqtuBwl9evSbDbXvZbtk/vgcwDA0Xl2HqMooj6kv0wmrdqNjY3G5eHhYd0Hz0G3l6Dby8TnmXZ8nzz3vsv73fVtdOol69hszUe6fe39+/Zjenpm3QuczGLfCmAfHe8H8PpuJ2zbth13fOfO1bE1W6ouQWNPJVO6jieRyq2o9yUc0eX4tWyadp5euDUvh6eXtl6Py/blazakrlarqbrv/+D7cfm//tc/U3UPPfRIXK7XZWSOXnoAWClLn1FKXztJx8PFYlxOmJePF6AdIy/cleXluDw2Pq7aLSwsxOV8vqDq6g0Z/wL9wC0vLal2qWwmLmeyWVU3PDISl6vValzevXu7aveBX7s2Lr/zHe9QdUNFGVdEzzYyD9e3+E0wC5XfuZauq9N7kEqlqJ1+v7mPrj/Qjt6xVhUa0q5WrauaZHvNvOtdv4hOOO0bdM65651zDzjnHpiZmT7dlwsICOiAk/myHwDAP7Hb2n9T8N7fBOAmALj0sst9Klq9pHP6FzKB9cXP1U7WH0DkjXhLZWfEHD5ssphtxuHplzuK9DiqFRGz0xn5Ii3RlwsA5ufm4vJnPvMZVfc33/ymjNHcZ4W+Xum0fOXKZf0LX6vJr3p9WV87SVLRHP245vNF1S5KyrUjp8fRaDbico6+vAuLC6rd3PxsXF5c1l/sRJJEcFZ5UvqZJWiOkyn9Ok5NTUkdqRDPPfO8anfLF74cl+/4xjdV3Wtfc3lc/uAHfy0ub960UbVbJCklmzGSZcSqQOevvhLjT2AvTKk8qiLq2C6RsEv32Bg7S7sn82W/H8D5zrldzrk0gPcBuP0k+gsICDiNeNlfdu99wzn3PwP4NoAIwBe894+dspEFBAScUpyMGA/v/TcBfPO4DQMCAs44TmqxnygcgGRbp3BGH1Y7lEYXh+tsQmIkupi89LH0ktRqERqNCl1WT0+W9NfZWdFXf/CDH6h2N9xwQ1yen59XdfMLdGx09kZDdOVEuUw1+q6z2VynLpCjHe1GU+65XFlW7XhfJEv7DwBQrcocVMqyJ5DJ6naNhuziJ5J6IKxTlpdX4nLB7NrzPkUFBmxipOc3VCypZnMzsl+wbcs5qm60NBGXb/vG38Rlq7O/++qflwOvd9KbZDmKjAWI55F34LuZIrtBW1wjW0vjWF8D77o+ehpBQEDAzzzCYg8IGBD0VYzvFR7GIaGDWc46LigbnbNiE5stqA+v3WrSaXFKOXjwoKr70z/907j8rW99Ky6ziQjQDiBrvNNIXWkYb7JOnnct065MIr518qhW5NojI+JNlknquWrURQRv1Bod69jk1WhoR440magiI3KuLMgYR4bFw41FfwAYKcgYF+a0ypPP5+NylkyR3oxjhRyQHn9cO3C2mtxW5uBNb3qjajdPZsXSiPbCS6bk3rx5X6yDjLR7mW7oXfru5pnZy/XClz0gYEAQFntAwIAgLPaAgAHBWamzr9WDSH9lnWmNuuQ7VnGfTXIH9S2tr/63//btuPyJT/xbVTc1dUTGwdFgxgxSZxOaieRi19FksvP0JxKiJzYaWk+skV5uA2FYd5snF9DImMaKBXGfXakYoxebjWgcVaPbFynCrLysdfEoKWa6SlXqUsbWWS7LtXOFvKpbJjdkNh0mTTBNmlyBR0aGVN3UUXlm00dlb2XfvhdVu//vlpvj8nfv+o6qi7zMRzddmd+JbsEuXXGSenk3hC97QMCAICz2gIABwVkpxq8Fi0pMFqBbdYs7blG8MktDf/CHf6jafe7zfxKX2aPNHjOxgjU7tcgDy0HXccxz2niusZjGonsioe8lSyYpFvftefkhEWkXV1ZUu/kKmaS8/s1PZcRDj6PomtCiOpyoEKmsHkelLNfLZkXMrjd1H4URqSuX9Rg3bNsUl4sUm//Uk8+qdjn6Zu0/oAMvV8oluTZ5Bo6Pj6p2+YLcc7doRBsRx8+MiTnYhAtoEb+bOZZfar/GtNwZvagJ4cseEDAgCIs9IGBAcJaK8Z13HZk8YO1upZQza4I7RCT62te+Fpf/y3/5z7oPx6K0FuNZdG+yiGXaZXMiEkaGUqpKFFCLi5p4QvOZ8Q4wDNijUIt6LQra8KReRBm9092gcVgJsNWQPhokdm/ZsKHTMGCMDpiDqAmNhuyk52luVutEtF6q6PmoNaVuelaIOFKGBsyRpaHe1M+iQqI704U9/6LejT/v3F1x2b5XrHpZDj0+1px5hnbNRizx+JX6ydam3mnXggddQEBAjLDYAwIGBGGxBwQMCM5Snd3C91DWepElgZyZEY72z/7n/0Qnab1I6WQ26ojKSdLjrF6OLpFt3bysOkU1WfMakylY3TBFJp8U7T+Mb9Q00CvkhVZd1NFmObq3YSLDGCvob8M4UT23DOHDckn2CGbm56SdIbcs02nOzFWmIEQXy+TlZ4LekKGIuHrN0C/THI+USjKOum538OChuPxnf64pvj/4gffFZbvnwDTc/O5Y3Z7RzXNSvREnoLP3gvBlDwgYEITFHhAwIPgZEeN7QycPN0Dzwj3/wgtxuWmCTJhLjbneAMCTqMqiWDezR7PZ2QuqmydVFEn/SZMhh3nj12QB4jIRN2Qa2jtty6SI4NEGbZYrZUUV2L5BxP+xIc0fN0rHC4smmCYldS/sF6+2laYe8NS8qBMlYx6s0beotkTcgOYbxWZWTVah6/j5VY25dIQ8+X54zz2q7ld/5X+Q/gy3veINVKmsOn9H16TA6iCu9xw8o0/qWBW+7AEBA4Kw2AMCBgRhsQcEDAjOgM6+vn6rzU6diSTZxJOM9PBZl73v/vtU3Xe+IwSRLSKscMb0xmaulNHPWA9ThBJdou8ada1DtjjAyZLWk3trk7O4epOxsyXmnoJxCy7mZYw7JkQH3jKs9x92bBHX17FhrStPjok+n6M5yGe1m2qK9i3qdf1cKzUZ/0ROuNvLNa2vzpXlWpWW3pvYe0CIJ8ZoHDVjunrxiJBSeG9cnMm1dpHNjWW9xzBPefF++tTTqu4Repc++nu/p+quvfafyLjI7Gcz+zJpqH2/Xw4phT0n3gfo0tdxv+zOuS8456acc3vob2POuTudc8+0/x/t1kdAQMCZRy9i/M0ArjZ/+xiAu7z35wO4q30cEBBwFuO4Yrz3/vvOuZ3mz+8B8NZ2+RYA3wPw0RO5sBVl2BxheeM5EohF6RXjLcU841/84hdU3QoRIzSpP0tUwOJWy5rNSEJibnjuD9Apjy2JBqcyhqkD9RNRVSHS4u3YsJBSnLdjk6rbPjkWl3dtLMXlyaIxrw3J8VBOi5zJJJsAKbWzIWTw5A1nvxotcnMbLwpXXaWqxeyFshwfni6rumhSzGEbiFxi1nDPNxrSbnpZj2SevPdcJOMvFEdUuyo994IxuR4+KOrEX379G6ruV371vXTUOVJRpXM2r1WC0z6TWmlF9bV5EqiPLqa+taM7MUx6749lUDgEYPJl9hMQENAnnPRuvF/9+em4K+Ccu94594Bz7oHp6aMne7mAgICXiZe7G3/YObfZe3/QObcZwFSnht77mwDcBACXXXa5PybOdCMBsL8dvAPPqY+YlwwAnnnmmbh8//33qzoWu5kfzAaqdCOeWCEeN2U9sEQF9Btqs342SQR15j6HMhLQMUw739s26CCWi3ZticuvOEeL8aNDsjufJ5Uhb+iu8xl59KmU+c3vQNftTEotJvqwVo1UggOF5FpGQkZxSM4rFvWzKA4L6cXROSkPlbUqAKLTPrrnCVWVTckFm2TtGB3Vc9rKydzv2DSh6h7Z82hc/u53v6vqHn744bh8yatfFZfXeEdy5mAbCKPmdX1qaqBHj7rT4EF3O4APtcsfAnDby+wnICCgT+jF9PbnAO4BcIFzbr9z7joANwB4p3PuGQA/1z4OCAg4i9HLbvz7O1S94xSPJSAg4DSizx50PtZDunkNWV3Fkx7D5rVHHnlEtfvwhz8clxco9RGg9fs6ebXlDBlBocg85toUpIgn6O9rs0P79csA8qSv5ZK6bsuYmKguOGd7XN69VRM9bh8X09v4kDaH5dJMXsgmQDtEJtEwnoK0VcHpig0FvtI9I0OwATJbOiLFdNZ6xAQbJW0ezOdl/yFJnPXVqja9DZGeun18TNUteko5TSmpeA8HALJE0rHnae1Bl6I6JsAAgC996Utx+T98+t/Ltep6jGkiBLGemfwsbApxBr9/1tR2bD110+qDb3xAwIAgLPaAgAHBGSOv6Or8b2SRBHlqPf/883H5t37rtzp2YU17bG5jk9rwiPakmp4Vrjorxnv2eGt1Dsjh8RaMmjCSk2tPFLUIvnuLmNF2jIs6MZnTv8kjKRHPs0bsy/EjTYvoWG/pSY0opZRNL8ViJme2asCaGEn8NN8NR2K9o/lJWO+xlIwrQ6ZHAMiSR2GrJeEXqZw2uVYbYvndW9XPbGZqNi7nNlA6qTEt7u8/uF+uaz0KSU2YKOjn+fWvfz0u/8sPy/t43rm70Qnd3n0Wz0/E9Baf10WOD1/2gIABQVjsAQEDgrDYAwIGBH3W2V1PLn/plNaZyhVxU/3oRyW47pprrlHtbr755rhcMiYSJh7k3F1zxkRXrhjiRAKTNbSIvCJt3B8LeSFbLBY0SeNG0tN3bxxWdbu3bIzLm4ZEfx1Kar28QHp0Lql/r1mPVlNt2jkOveqSM4/LUUpH3zkiwlxrviNCTo4GW2N6ozpD+BDRxYsl2aeoNjV55o7JUlxuvPoCVVc6KHswT+4XbvjKon4PFxdEt5+b02QhedpLKOa1eZBNt5/61Kfi8mf+w6dVuxGKVLR58RLkUm3JTk4lwpc9IGBAEBZ7QMCAoO+mt2NivBXn+ZiJJgDgscdiRizlQWe95NijK2VETjZ3HD0qobY1m57Jr29eA4AGmd6SZFrKpDUPXJrE24IxJ40PEyHD0JCqG85KPxmanqxRE3IZ6T9ho+rYpOaJFMGI6kyYYAOUOV10lKJ7S+n7bJHo7hPmVaI5aNFr1jJueAm+N8Onx1F2GVLt8kbSnSBeu7nysq7cJ8elgvTx5H6dsnl0RJ7F3LJ+rxrkiXjo4EFVl6NouXvvvTcu33jjjard73/yk3HZmtSYO5E9FrvlFeiWOqwTwpc9IGBAEBZ7QMCA4Ix50HXblc8a0ffOO++My696lRAE3HZb5zD6itlVZxGfgyDqRqRiPrmEGSNnbk2T2GrvhEXmYl7vxk+OS1DLUF7/1iZJnk6Rl1/KUE47cmvzJgDF0667EuxMuiOQ+O+9UQUaMieeXN4sEUeSxG5nUlR59ppzIj67lH62SXrWqawR48k7MKK0TpbKuEDntdImVRbxzt1930NxefeOLardTw/LTn3deOGlkzR+805wFtf5ecmGy5YhAPjd3/mIjN9YijgIhwNhuq2RNcFiQYwPCAg4hrDYAwIGBGGxBwQMCM6Y6W0dTZeKWv946qkn4/LEhJABHp46rNpxZJv9GeOgr6GSeK4tEK84AEQUdeS9np5mS+o421E+o/XmUeJo3zymI7RKedEp82k9SL52k3SwqjEPJj3p88Zuxmq1uhcz3938GFXEmorCMu3YtBdpfTtB6ZdTaSLxzOg9jHROjl1kvQGJfLFB+yxV4+HGxBBzS6puw4jow+dvkXfnuUPTqt0BMqtG5rnXKc20JZdg0o5aTXT9K658o2p3kEx2JRNpWaf9lCzvPzQ7k7hYdT7RdstzXZ5s+LIHBAwIwmIPCBgQnAHT2zEPujUJg+JSZMS5ceIVe+ihn8Tlmkn/lCPx2XKMVZYW43Kd+MEMcxoiEoOst1dE3k3ZnFxrtKQDWjZPlOLyplEttmaZKMKI52wdKyuSOy2aZSFia9bcQIIyvKo5ttNNaoKLbCfUTPVhOmFxP2nE+Kx4pLHonsxo8odEWsRsm0YrGbFKJWWX1XParMq9bJjQfH15unZEz/Pg1I9Uu80TEoQ08+JLqq5O5rWkZd+g94UJU55++inV6qKLLorLLfPcOZiGzZ4WOpWYVcs6qceC8GUPCBgQhMUeEDAgCIs9IGBAcMbcZbvBuv5xBNvUlJAL5guaSKBMudhsDjffQUdNWOIGMrNYIsYskSsUckxooPXVQo6IMsz+gye9tGmYHOpEqs5atDc84w1S7hsmAixF6ZbZDHN8Z8pe0I3wUOv9SdLFU2QSXbM/wPsRZm+i1aFd2kTH1Rti8mLXUwCol0Xf5uc5OaFzvU3XheSiOKT3BOYWpQ9v0myrHIL0nrIbLQDcc4/sEVzx2ivQCewia0lTu7nE9kIK00v6p+3Oubudc4875x5zzn2k/fcx59ydzrln2v9bl+WAgICzCL2I8Q0A/8p7fzGANwD4befcxQA+BuAu7/35AO5qHwcEBJyl6CXX20EAB9vlRefcEwC2AngPgLe2m90C4HsAPrpOFyeMakWbzfbvF07vxUUyoZlIrsktm+Py3NycqmuRvOvrIiA2jWSUpIgyS4CRpYiyLInLQ0aMHyETYNIQjrVozN5ItE3ymGpGTGKg27EYbynLUsqTjX/LO4uA1rtOH3cqa7Nc0wwyYnc7Zb4zEXxkzrNRhpwKm6Vnl7AmUTJF5rQYX10Uj7ohUq+yad1HvSYqYGlEk4osEJkFe/IBmued8wVce+21qt3NN98Sl69641Wqjp+n6s+YOm2kG+OUiPGmw50ALgdwL4DJ9g8BABwCMHkifQUEBPQXPS9251wRwF8C+B3vveLt8as7B+t+Opxz1zvnHnDOPTA9Pb1ek4CAgD6gp8XunEthdaF/2Xt/LN/NYefc5nb9ZgBT653rvb/Je3+F9/6K8fHx9ZoEBAT0AcfV2d2qMvB5AE947z9DVbcD+BCAG9r/d6aNkb5iPcS6s7J+Yllm9uzZg/WgotzMebZ/1ouYvNw7oziTqSxpGGKYej2XkoO80f8KWcorZyL4mK/dmlKY7JLZY9aYYFqsz1u9jkyMrOcak1dEewlJQ2jZcuvrjYmkfV3YtKd1xgSxu6ALUSInk/MmoqxJOiqbvKyrdUTXaiY0Walvigksy3nlzGPP0LNenplXdTmKRFuu6f47kUDu2LFDtXvu2efisn2/OZ24MhGbubI6/ImiFzv7VQD+JwCPOuceav/t97C6yG91zl0H4EUA165/ekBAwNmAXnbj/w6dvSnecWqHExAQcLrQVw86730sklqRpE42pCHDp85tWaQt5HUEFUcndSXg42sbkVAZN4yHW4o8sEYKYuIZLepxRCAvuZq2jaVJF3BOi63a7MKEkN3SM1niQRYrSVZNWDGb0zIbLnfmjec0Tmauml049lucbpmaJSy/fBfTHov/nsotQ5DJt2ZVkiKlWGaHyFdedJ5q98PHn47Li0tzqq7BKaqs+UsRhMgFbr/9dtXsvb/63rjMBKoA8J73vCcuc5qyE/GgO1bXzQIXfOMDAgYEYbEHBAwI+i7G213yY+Cdx0cffVTVLSyI11yBsqImDVd5mQgq1og8KuCC/24CVdR5WmTLpmW6SkPiJce7vAAA2gG2gTBJ8rxLmt/aVJLFZ+Z+M9z2ipvM8MaziA8W6U0W1y6qDGddbbAXW8PwrxHhXRRpywj3ofq3qgDvuBvxnC0NrApY8ZZZP1ImMihBwUUO0q40bLLrjktoR2K/tiI3iCTFziM/Gy7zDjugA7ieevJJVfdLv/RLcZnXR2TUq27pn7p51x1D+LIHBAwIwmIPCBgQhMUeEDAg6Dt5xTHz0sqK9kTi4+f2PqfqCoak4hg4Am618846DR+xucqvyVfMOdb0ngB7UrH+7oy+xJ5rKUM8kSLSypTxrktzymnS7W071uebJvKvTjeaoLxniaTVNclTy/zkK52Ydd6ENf3QfBvTXkQeaTXSo5tmzyadJX5568nXpL0DmoNWy3hH0kZFomXNmVLO0BzkczpSkfcfmkbvVzskNoqxtb5HZN2EI/LxE088oep4vruZ19g020uU25rzT/iMgICAn0mExR4QMCDou+ntGGd7raaDAQ5PSXqc2dlZfV4Hb11rqmHOtYSVTUk80kQLWmxKcqpkIyoVU8RBR2Jq0aQajtCBuAFAJhLRupgywSl07XSGHk1Ti62+xWQHqkqRK7RIkkxEhq9ddWj6oHvzKk2zCeohFSLZ0JxraMjzrdVFTE3njYmIAoqQ0Oa7Zl3uhaVnb66VIJNgrabVmjTdqaN7Gc7pV39iRNQJ19R9JMi82TJitnrPyCQ6Pzun2k0dllRlb33b21Rdhe6nQCm+1wZK0dzZd7992I1rMHzZAwIGBGGxBwQMCMJiDwgYEPTZ9OZjgoLFJU0QwCap6RlNX9Vsra+JZAxHuHJdNEySzFHIaXabph3r6cN57VK5eVzyiJUK4g6ZNG61rHunslpXViYkkx8tV5TrMUd9s6r3N5IQXbZW0ebHFEXSNeuk2ztjoqvKsbO89ES+gZT0Z6xOcKQrJ0x64RoRNKSIXKJeLqt2DRpjKq2fJ5uXmEhkxaTZdhUhlUwbc2mlKSZd15RNjEZd74NceO62uFww7s+VGpnGbNpqMoPye2UjNycnhaLxF655t6r77l1/G5ev+aVrpD90ho12jJX1bsGeXfoLCAj4B4Sw2AMCBgR996A75rF2IlE7zN/O/F32HOaZs2YLvh57IjXqxozj5FpjIyOqrkiefOy5liwY8goy8Tz97F5VNzUrKopN6zQ5PhGXd2wVsXLjSEm1G8mIiNio6/sczYnIvFKWucpaLz+ag8jOFXnKtSIioTAmLya9qC7puiyNo0omwFnj9ZgksoZH99yn6pYW5+Ly0JCoTUvTOqVydVFMtW950xtV3cSw9F9ZkXuxz33HdpnvXEarAglSNVpJE5lH5TqZ7A68dEC1e2XlVXF589atqu7Ou++W/uk5Jbqk27LrpytZS9xfQEDAQCAs9oCAAUF/PeggYordrWTxxQYKcBAB00eX7c4uidbd1AQWeRJm+3KE+OSGTTZP3o3OUZqhsqEGXlpZjstRSnuFbdgi4uJLRzVJwp7nROR/9EkpjxSGVbsh2rWeNKmKNm8Qi8HmMVE7Jp1+1EnaRa5VtUjbIo83TocVmV3qFvWRivRu/wtPCKfbQ3vkeb50ZEa1O3z0qIzDeFU26nL82steHZd/+ZqfV+3yWRG7f7rvBVW3Mi9zvHmUCEeMJWc0kmd98QWan27qISGbaBirQ4vmJ8nqoSHYOEQedE8+9ZSqe/7F59c9z3qBWjILxilP/xQQEPCzi7DYAwIGBGGxBwQMCPqqszuIl5HljZ+YELPTk4aQj8F6S80QIfQc0E86uyUjmBgVc9uYISXMEBkER1fVqiZvMnlSpTJaN0yQ+WoX6dcAcJSivqbnxCvs0JGjqt0B0hv3GkLLLO1pvO7iV0jFNp1kd0OeCTMNGSWRPLDemDYprNlLrrKs9x8OPSdptu/5zrfjcnHDRtWOLYLnbNus6i599YVx+RW7JZ1SwaTlymTkOe3eda6qa1Tm4nJ5Vsxh5fKSaldNyEB2GtNY4if0Plq9mb07qbi8vKyalSuyv3To8CFVt7IidcqEZl7nbqmhesFxv+zOuaxz7j7n3MPOucecc7/f/vsu59y9zrlnnXNfdc6lj9dXQEDAmUMvYnwVwNu995cCuAzA1c65NwD4AwB/5L0/D8AsgOtO2ygDAgJOGr3kevMAjsk8qfY/D+DtAH6t/fdbAHwSwGe79eWci01n3gSPcO72huFV62RyiAxnGafmSZhz2POOBaCMEWHHS2LKShneNiaNSJJJrWqcl2bnRUSMjBhfIO+0HLR5ZuuopLQeLpSkXVGb3l46ckSubfjSqsSN/vg+EVvTZozLJel/28aSqhsZEW+1IWpXM9fKkZnyIIntALA0Jcf/6JKL4rKj+wIAlxMRvDSqPRbTpDY5CiCqlLX6NjsvYnArocdYyHCgDXHyOf1ciPMD2zfp1OLMXVdrGpWHXyZ6//I5mxJMGj71mDYtl4bk+R44IPO2e/s55lqdORZPmQedcy5qZ3CdAnAngOcAzHnvj83kfgBbO5weEBBwFqCnxe69b3rvLwOwDcDrAFzY/QyBc+5659wDzrkHpqdnjn9CQEDAacEJmd6893MA7gZwJYCSc7Fb1jYABzqcc5P3/grv/RXj42MnM9aAgICTwHF1dufcBIC6937OOZcD8E6sbs7dDeC9AL4C4EMAbjvu1ZyLTW7W1fXBBx+Myzaajd1lrclOtSNdv5DRxBBK36G/Z0yE0xBFtjlDENAgN9IlipqaNgSZy0QMsbKgTTBZ4mEfzusxTm4VU1xxSOq2j2qz2WKDTDAruv8a5SWbq8gYnz2kzXdoySyMTYyqqtGczEFxTH6gfULvMSzQfWcL+l627xC34Nrhubj89KEjqt2B2Rfict3r/jfSuP7Jr/xiXH7wnvtVu8U5iaTbulOb7zaOy7i2UNnqvEnaSykZN+k0mWej5hp7WFx8xXnnx+X5eU3OcvglIVR985verOq4xx/f90Bctjp7N8T308Ui14udfTOAW9xqsu8EgFu993c45x4H8BXn3P8N4CcAPt/zyAICAvqOXnbjHwFw+Tp/34tV/T0gIOBnAH31oKvX6zh4aFWcKRa1qMQpcGo1HYXFxyzi1007JrnoRobBRopRMi0BQJYIJWxEHBNWcBrp+XlNyDCzJLxnmYKOSquSGedFEwH2yJSIfkvLIo7v3v0K1e6Sy6+My3d/+zuqLpmQOVghe9JcRovIR8nDa8FEvW2lecwOixmu5YyZb0ZE8qR5nkdfEI+6g/NyrXv2PKPaHVqhPk2EYHK/eJrtnVmIy2PGzLRlWOa4abj2hnKiTlQpi7KhjUeO1L4NYyVdSe9mo6r7z5Npddd28fJ7YlGb18hBD1Mk0gOAJy/Iw4e0d12viE1vgYMuICAgLPaAgAFBX8X4ZBRhbLQEAPjarV9VdY89ticu1+uaxKBaE7HYQzyTsoameZg8kZbNLjXvrDMnwMYNeic6TQQNkdNeeHXiIis3pL+ypa0mcgnrXTe/JFaIbefs1nUzIvoul0U1uOhVOrgjSZ6DR02aoXwkddmCiOMNkwm2SvNRM7KfJ0+ziAJm5mb1jn5E3m+oaBF8pSGT/Pc/figuF0p6vi8+VywNiyuWvEJE/C2bZGf647/5z1S7T33sd+Py/LwWkc/ZKl552Z0ShJPwJl0V7bKPFLR3XZHIMZZrhvOPOAtnfyrceMWizjx8aEE8RMe2auvK0lGy5tRZ/bRb63JsHeZ6cKALX/aAgEFBWOwBAQOCsNgDAgYEfdXZDx06iD+84f8BALz//e9Tdf/4zcL3/dWvfUXVsY7NXBPWRNekdESpSN8a/6olidd9KN85lbGNtmuQrpwpkh3H6JorRIwQGY+/EUob1VzQJrt/fNkr4/LSypa4PK6tWqiSjp2w4WxMikl89jaDNd9oJqd11CSRMXLqo0pdmzOLwxIdls7oC+zcJff2lje+Ni4//Oyz+lqQudq1QxNbZBJiDjt/9664fPCFp1W7i18lnmsXXKD3N84/b3tcdpSGyiW0x1+C0kEVnb7Pi8/bGZcLL2nPzw3UT21BzIPzLd1uISXP6cCs9iL0MzJXmZTM/Vo9vLPO3tV1ro3wZQ8IGBCExR4QMCDoqxi/efMW/J//5t8AAJaXtAj72J5H47INUmDxHGThse1WVsREZzOOcgBNhjKkWpKBBGcONbJvgjKEclqkzRs02cF427wIAKmcNsHMUoDEto2ag64+L+aZTUMyrhHLHz4k/V9ykY42PnRITE/Nlqg5SafHkSKevMjeJ5UbFFiTMtxvrKHU6yuqzrXk+IqLRQSfKOrAoyVSgeotQ+axTeYnk5FxJA1H/RVvFI/Cbcaslc/LmNNJkX1rFT1eT458LROQs3WiFJcXjurzdm0S1eOF/UI8sTKrOe4aRRH3Ww3d/+233R6XP/K/fiQunwjPXPx+dzklfNkDAgYEYbEHBAwIwmIPCBgQ9J03/phObEkojhw5ss4Z64BMDtY0xjpO0+h/HAWXJN17TR/k+hpF2r7BubxSeTGR1Oq6j+Wq6KEry5rEoJCkCKpFzbVeGJI+dxREX82mtJnouf375NpLC6oOFPU1VBCb3WhRR9+VyASYMs+Cj4nTAc5EEiaJoz5hiDg2bRNd9ugBcSPdOa5JJRdp6qK0YSN3oqcPU2RbJqfne+Icyc1WyFsSUjGB1WhfoWXch1NpinY0Gz5bxoiEdOcmVbdjq5BlzJflWaeWtWtxk8hO7vnRj1Qdvy8pYwbtBEsweWw9uS5Ke/iyBwQMCMJiDwgYEPRVjG/5Vpze2KbM5UguK+InKLi/0STudpOEhsX4rOGgq9dEnOPotVRSm4JaVWmXsFIlRYoxp3w6oadxKC9iX7mmOykQV1uyoc04k1lpm6NrLZrUzgdfkPS/rq69CJk/bctGMUPlW1q8K5DIHBnxvMFptVo8V1p89kTm0UrpOchQaqtxT89zWJtcE1uEgTxl3olUSUT+PJk3veGeT+Rkvr3XnPJNOlTEFi1NxMFaX6ulTXuNeSEZ2ZjXzzNDHozT86KKpnP6/cs02eynn1mS3tVLLr00LltRvVv6p2N13YLfwpc9IGBAEBZ7QMCAoK9ifCKRQKFNhrBiyCUuuOCCuGz545Q0Q+V0RotUy0vSp+VES5PYWifRl7NrAkCag0zMTn2L0h8VaNc0YXZ2k0kSsRLaQ69IhBLFpN4hL9JpLGUuLWhvrKVlOWbqawDIEfHCaFbq8k6rKyM5SoXUMsIfiee1CsnBKS06KuuH069SuiQU1BGpOW6oqNrVl0ltSurnGRWF6MLlpZwyYjzoPfANsxvdorRfTRmHN8+M+QVbJjtwijzqooZRE7yct9yU92q5otWEGr3Ss0emVd3EhKg8l7/2NXg5iNdMFxaL8GUPCBgQhMUeEDAgCIs9IGBA0F/TW8uj0taHrHlteFjMLFdffbWq+8Ydfy0HpCdanX1pUXTZptH7ExTlVSOPpZkZnbppaLwUlxvGC4/NbVwuGO+xTEaupfR3AClKoZQ1HOe+KXreLO0lHF7UXnh18vAaHSmputEh2QfIEv+71tiBNM2Ha+r7bBKPvKd9Cpcw3oa0p+HtfKelLkUpoOvGKzFBKbPrJh0yIho/pViOrMmVvlnORPDxvgJH97WMp1mNTLpp40H3+sslR8rDDz6m6nLk2Zei8vzRl1S7eovG2NR7MP/i13+DxoueYE1vvaR/6vnL3k7b/BPn3B3t413OuXudc886577qnHkCAQEBZxVORIz/CABOc/EHAP7Ie38egFkA153KgQUEBJxa9CTGO+e2AfhFAJ8C8L+5VZnh7QB+rd3kFgCfBPDZ4/QTe8pZcok88ZPPmqyoysRDmVQTltSBxUpjgkiRh1e5InVTR3XAwqYRMdnVm1rMTji5dpW47bNaCkarJdeKIi3wpEABOeandoXMP4tEPLHg9TjYrJiE8egicTFPqaAiM+E54obPmQAUDoRh0ddbfnm6l5QZY4u4/lNZUqHSWtxXLOlev45JUtOSrHagswmwZcyInvj9QaQRRptQ5rbyovbymxgT771MRptSy03pP015C5pOi/GNGqlDad3H+973P8o4yMyXNOZMlYn4BIgtjqHXL/uNAP415NmMA5jzPn7C+wFsXee8gICAswTHXezOuWsATHnvHzxe2w7nX++ce8A598D09PTxTwgICDgt6EWMvwrALzvn3g0gC2AYwB8DKDnnku2v+zYAB9Y72Xt/E4CbAODSSy/tIUlNQEDA6UAv+dk/DuDjAOCceyuA/917/wHn3NcAvBfAVwB8CMBtx7+cj81LzkRQlVdET3LW/ZTcLZkrvtEw0UPUZ9OYkzgvXIJ02SPT2qy1vFV0K+PZqdxKVyqis7MuDwAtT9zflrCd7q1piA0XiZd9oUJ87TXtegnHqan1XFUoZ1mWdODI7Cs4MmvZzQNjRJNzTIRgk82gZk/ANcgNFrLHYPuIIjFbpgyXezYj5yWI69+SirAPddO4s9ar5JZdlX2E2rI2f3HUpdcTgHkiR03ntXvy4/skxfLsolw7V9AkHY2m9FEaG1Z1W7dLWulWky/e+T69GWQvOvzJONV8FKubdc9iVYf//En0FRAQcJpxQk413vvvAfheu7wXwOtO/ZACAgJOB/rLQeeAZNsEtrKizRszc2ICGx7S0WAgUZU97yomYi0iMd6Kt8vLFP1E/j+VqlYFXjok48gbAozRAp1HZjJXMeIWie5Nbzy6SFxMGy/ClQrfG1UYEbzZFHG0Yfqfo3C5NM0Hp7MGgCyRK3gT3ZdgEZ9MeUkjZi/THDSq+llkSBmokMTcsCbRPI3L9B+RByB76xlHPjQbMlmNmo6mbNDFW1UpO2hT4fIy89PpOd374nNxebGs1YTnfyrEIvNL8i79xnXXq3b/8cZPx+Wr3nyVqiuT2S9Fc5/oIsZbxKbmLrtiwTc+IGBAEBZ7QMCAoK9ifLPZwmJ7Z3NoyKQmpd1EFqkAoEHiItNAVw3JAAfTVCq6LpORHfJymbzfDO/ZPHlP2Z10DrLgXdN6Te+MLlLwyJpMs0TQkElpeXSWyDcWl0Qsbprd4UpV+jfxJ6gm5A+TJXm8SaOSrND8tFp6rhrVUlxOk7faplGd5mquLM9pcV5bDCpLYuVYnJId63xRe48ViKs6VdT9R7zBTBaUprHC1FbE47K2NKfqWrQb72invlbW75gn3rmmmfDLXntFXL7rBw+ouikKpEpnRCXZOKEz0kake/z8O9+l6tLkUZdilcqaBU4S4cseEDAgCIs9IGBAEBZ7QMCAoK86+8LCAr773bsAAG825oc06dRHjQ+9JbroBPYiYo8oQBNORpHUtWraZDQ9J+mUysr+BbQo7S5HXllvvUZN9L96TZt4apHomzb11AKRcFYpuq+5xvTG9hXdR5Wjq2gO5pa1SapMXOhDGT2/Y0Q2MTwseysHzUAqpOd648DVpGizpaPCp95cNKmmyGSX3mxsamSKq0Pej3pFez3WFoRHv7asIyYTxM3PzzprIv2mp8TkesFFr1Z15WW5z7EtW1TdkbkfxOUP/e6H4/Kf3vQnqh1f710/p3X2iL33aCItkSm/3zaq83R70AUEBPwMISz2gIABQV/F+Hwhj8tfs8qL/aN77lV1u3adE5f37dun6rS4S2KOCb5gU9yI4WabmxXRb9Mmyrw5q804deryyMyMqiuRGJ93IqY6ayIhMbvVMDxzxEnXMt57tdr6ortvaJGN40Aa5tpNItxYLovYWq7rcex7Zm9cnhjWZrkSmcfSNN6JTdqcdPf3vx+XX/HqV6q6Hbt2xOVMWkTwxelDql2BvOQqeS2CJyMJOqkTr195ST8XrMixr+oAF87/lCLRd2VJtxuiVFNI6WCdGr1+83oasf38i+LyfQ9IFPhL+3UQ6K9/8P1xOZ/R5l6Oh2Jrb0eeuZeJ8GUPCBgQhMUeEDAgCIs9IGBA0FedPZPO4JxzdgMANhsTxg03/L9xuWbIGppEFDg6JjnEpqe17sbc8GljWmHzHZetQ2JxRHS3g1OajHLLRCkuJ9M0dYaEIuLUuiYKiS0mTROZl6D9iIjzixmfWMXzbvrIErHmCunslUVteltcEZ21kNZ9HD4ikVx5SjF9DunhALBlM+nwZv9kiHK9ZcjvdV9Nu+YulOVZJ8sm7x65vjJhY6u2oNpFIL08YeyUDd4HoTmNtF5epei+lYae7xUybx5c0GPctmtnXP7v9z4clxPmuf/TD3xQ6iyRJJOzkCtw4gRW5ynljQ8ICPjZRljsAQEDgj6nf2phpR1tlMloMeqFF1+MyzXjdZZMrT9MG7GWShG5RFl7v7FZrlgUD7GFBW3umZyU1MDPPfG4qpumCKfsmIj7SeMJl+zAu25hLSnM7c5eVZbXPUd86hXDbR9lpS5N81ZPafPapi3C/D2a0+NvkNqQK1CUmkll9fqr3iDXGh5VdQ3yUhzKiqlzs5FNjxwWU1wrpZ9nhYgnGpW5uOyg1Tzn5TjR0nWeRPcmcfxVDc/99AqlvBrS785SXeZn3qghf3evmNvKVen/qivfqNpd+irxylsTzNbhHbFecj0hkFcEBASExR4QMCDoLwddIoFMdtUr6sEf36/q/vZv747LVnz5zd+UAIMvfvHmuJwxhAx18hKrN7Q4x4Ex8/PiTWezvQ6T512+oIkWjhyV3f9SVq6dyVl1glQUS7HMY4r0by3vxic5C2pSi/ENktWqRmxNkIhfrkl/haImC3Fpufa2TWOq7sLzZNe92SLK7LR+XRpMi13X3oBMf50rCKlDYXKnatckwgeY7KaNigREpcBkHloEV3FB5nmq7LKkXnmvVZf7f/xIXF7+yVOq7pl9EmgzX9Pq5xwRjtQbMt+//eF/qdrViCwkk9XPok67/4kEB8XoOe3mQdeLyB++7AEBA4Kw2AMCBgRhsQcEDAj6qrP7lketbbq48cYbVV2KzEuvvewyVfdb1//zuHzH7X8dl2fmNIlBkz3QjLmqMjsXlw8clKi6sZI2GTknutxQsaTqFimVdLkqemM5MqZCt74JDQCiblFN5GnGen/GplSm8/JJw7FPFxgdlj2H8rI2J6UpNdSOyQ2qbufmybg8PSvedEuz2mMxT6ShFRNVlxwW8sgWjcmbVFPDk+KFVzbEFtWqPF9P4YjWdJWkfRH79SLHOLBjXNNw1P/dg8/E5eenNBlljXT9dF7nBKvRfV/3z+Q9fcOVr1ftOO2V3SdKcBgj3dwa1nj6w8uJgOs1P/sLABaxmq6g4b2/wjk3BuCrAHYCeAHAtd772U59BAQEnFmciBj/Nu/9Zd77Y7y6HwNwl/f+fAB3tY8DAgLOUpyMGP8eAG9tl2/Bag64j3Y7YXpmGl/+0pcAAPf88Eeqjs1o55+7W9dRGqPNmzbF5cUVLZouliVAomZIIyIyZTXJXOWNJ1WDCCTyZDICgPkjEhhTJa74SqTNXznyXEtEWtxiMd6akFqUyqnRknF4Y0bM5USUbBpZr0njGiHCh5FhLX6mKf1RuqWDRxaPCGdcjrzmXNV668nFN1AAEQDMVTidEqk1OS0+NyhipFbWKcE88bdHoFRQJtrjWGbg9pGqS5Da4Lz0kS9OqHaH5qSPRqqk6lokxi8bXkJPgTaXvPLiuDw3N6faTW4U1ahlxphUWYBZjLffYtehfGpNbx7Ad5xzDzrnjiWxmvTeH2yXDwGYXP/UgICAswG9ftnf5L0/4JzbCOBO59yTXOm9984mVW+j/eNwPQCMlEbWaxIQENAH9PRl994faP8/BeCvsJqq+bBzbjMAtP+f6nDuTd77K7z3VxQKhfWaBAQE9AHH/bI75woAEt77xXb5XQD+HYDbAXwIwA3t/287Xl9Thw+TyU0LAhddfGFcvvSyS1VdPi/Eg/MLYo6Zm9emNzbfLRuedI5+SrDZwpgwVigNdMPosnXqI80uspG+Fzat1ExUGutazupZNBTlAWraLRBZok05vXmzkIJw9ODsrJ4r5o2fGM6ruhefkfs899ydMjzjLtt6SXT7+YWfqLoLLrogLo9vEg0v0dDkD0ukpydNzjlfpzraW0mYKMOmmjhrkqL9k6TsF8wtafPa/AKReUxqff7ovOwFJU3kH5OhlkqluFyv10072jvowjChciScgHtsL6a4XsT4SQB/1e4sCeDPvPffcs7dD+BW59x1AF4EcG0PfQUEBJwhHHexe+/3Arh0nb9PA3jH6RhUQEDAqUffySuOiddWNN1KnHQXXXSRqpslcf0gkR1YaSiXFY+x+Vnt35NW6ZFFzLZcdZzyKW34w9nvyXM0m4lsa9FepbNRb3zcMjdAh6xC2K3PlbKIuznj0cWqzeKsiMHlea3WpEi9SDW0upImc9h+ivjK5HUU4GFK0xWZ5/nCnqfj8hveIkQOm87ZpNpFZIlrwXj5kYk0AeKPW0POJqJvs6FFfDZfNclr8OiM5rFjq2Jtfk7VFYfES3F+TqcmyxGByubNQtIxPq7TTyvx3GpvnNapC/sEt7Mp0WKxPnDQBQQEhMUeEDAgCIs9IGBA0N+oN+9Rb7uxRoal5fLLL4/LYxu0vvMnn7tJDkhXqde02YnNETZls9J3SC8aHdVRb3MUHefSWmfPEpljgcyBKcMWA9IvW4bXHey+afQu8g5Fg/jD4QwhJOdzMyZGNvtFLUpNbfLFcUrl0RE931e97rVyHvHX14xv7o8f/ob0V9VzsJWi2X7w/b+Py5f9o0tUu4mtwpKTL+j7TJGLM+cEsASNdTI/Jg2xZp3C3mo0H08+p3OxFUvyPGcq+r1qLotZrmXNsWRis++SBplcjV7N7y3vZVlXa36HO5vaupj1uowuICDgHxDCYg8IGBD0VYyHczHHetOIQ0zWkM1pE89Xb/2LuLywIOYka35YWRGvqEZTEwQ0yZts1w7hTM+ltdi3l1JKbTr/XFWXI671DJERRHV9Lwm6t7VxS2RmsTY1FdREqZ0N2UGS5mrqiDYF8fxMjoqZa9OE9grbvVXMRFlj7pkmYs25OTFhjoxpcf/n3v4uudYmnc6rSYbKZ54T/v3xSW16c0m5dt2mymrKHLAfYso0TFJUpNWaEmlx0V6YEe+9p/fuV+1SZEKbGC2puqVlOc/XtZdfg6Irl8izMWHE7KGimO+6ebtxVbdINlsnx53PCV/2gIABQVjsAQEDgv7yxjsXi6C5lBbVd+8WwoqbbrpJ1SXJ+409jFIZ7f0WUcqhyOxK1mjXNJcRkW2UeOIBoEk7u5EJqiiNUmZSEuNTRhxPEn940kpVJH5ZMb5T8ItVSbIUhDO5SYvFI8SpV0yJCDtsIg6HicxixFgdJsflPjeQJ1hkePqLdK1kXtd5uvFcSVIfZTL6nustyjRL6Z4AgLUjTvVVb2lPO5Li0YTe0a8RQUiUkTn4/g//XrVrkifi4uJhVZfOyU69NyJ4k8T4o0eF3OTCCy5Q7VgVs4E8nWBFde7j5XDQhS97QMCAICz2gIABQVjsAQEDgr7zxtfbOcA2bdqo6s47//y4/Pv/1ydV3RQRIDqKeGIdHdCeZTnjSdWMRM979tln4/KObTtUuwz1P31Yk++kx0pxOVkgDzqzP8Apm5NdVKtuvOBe6fa6He8/pDN67yNDutwymeGqM3OqXWNRouMu3HWOqisV5d7Yc21xQUeK1cgLr+I0KUV2ROYgk5IxrRjSiByni65pb0BHnnLMqe8S2tTZUvkC9P5DuSzvxN/c+UMZn9ljSNJ+zLx57g1K0+wMaT3vJTDJpPVsLNKeidW3WRdX0aDmuSu935ide9Hhw5c9IGBAEBZ7QMCAoM8edIBrB4JYc9Lioog9Tz39nD6PRMkmneeaOvjCk7zbaOpghlRGxLtqWUR6qwowp9iy4aVfyslxjUSqlBWpyI0rYbzfwBJo1FmcY2kuYeQ5R+0aVS0+84mFApmrvG63QBz7Pz2wT9cRQcMQqSvMvQ8A6RURhYvjOm21a5AITiJmEloEry7KM7QqT4NE5joFBkU2QCQl1z64oN+JF+dEjL/7J4/G5bm6eS4z4inovX0uUt69c5eqe/755+Myi9Ys3q/2Sf0ZVUAd9xTs0sWDrgt9fPiyBwQMCMJiDwgYEITFHhAwIOirzp5KpTCxcdXkljY6DZNKtozO1CTSBFVj9JYm5UTzKe1K2ySzHKVUQ7mqo5hyWdFRl5e1++b+KTHJjG+Q7Da5kiZ9ZBXMe62j8h20TPSWJ10/on2KNbnN2DpjogdbNAeNBBE26umGI7LLReOmWiUu98Vl2etoOX2toVG5761D2pSaqNJ55D5s1G1kyQW3YRROTp/dItIPm7K5WpY/TFf0c7//mZ/G5Xkn11oxZB5ZstgV8joN9i/+wrvj8u7tW1Xd5z73ORkHkZU2TK5BR+ZHmPH3RkqhYSMhj+ns3Qgrw5c9IGBAEBZ7QMCAoO9Rb8d42nft3Knq7rzzzrjs1zAQ9NZ/gzzLGoanjMkEOD300VlD/lAWkTZX0LIvp/55grzwsq/QKaY3ZCnlkBHB0zSuCNpMpCnm2QxnxHg1IXquGjR3ntIp5dJ6PorEoVeItDdZhsgxhkqUttrw+nkyxdUzWpVpZagtieCplB5HRONy5rnzM/Mk0jeN2WxpSe6z2tT9c/qtCptck9rTrkpc/IbyD5/4xCfi8lN7HlF1n/70p+Pytm3b0AndItYUb3wPqZfXg/Rxkhx0zrmSc+4vnHNPOueecM5d6Zwbc87d6Zx7pv1/N7a9gICAM4xexfg/BvAt7/2FWE0F9QSAjwG4y3t/PoC72scBAQFnKXrJ4joC4C0Afh0AvPc1ADXn3HsAvLXd7BYA3wPw0W595XI5XHLJKpXw7l1a9H3p4EtxOWWCGVQmVA4Q6SLy2CyanMqJgztm5nWaqEpLPLWqK8ZDj0SxJInZL5rACT8mO/XjOUOwQbuyqajzb63iqrPcbOyNZR5hMi/XSybkXkpF3W4DBX6MFEdUXWlU+Oq2ksfY8MSkareiCDZ0gEujIh56ddrtjwztdiJB6kpDez0yt3aDMuhWqnqnu9aS57l1u36vvv/ZL8flSeIQ3PvkE/padC8XXKi5B7/5N38dl1/3mteoupERmbtiUVSZjumZTgK97NR3a9HLl30XgCMAvuic+4lz7nPt1M2T3vuD7TaHsJrtNSAg4CxFL4s9CeA1AD7rvb8cwDKMyO5Xf7bW/elyzl3vnHvAOfdA1di0AwIC+odeFvt+APu99/e2j/8Cq4v/sHNuMwC0/59a72Tv/U3e+yu891dkDIdZQEBA/9BLfvZDzrl9zrkLvPdPYTUn++Ptfx8CcEP7/9uO11e9XseBA6tpd972trepuq989StxuZN3EKDNMbYdR6xZSnbuI5WS215cXFTt6sz5ntQ2mCa5bnFE1vSiJipIs+LU0t5YyaSQGOSNzp4hYk2OpLN6WL3BUVImao/ILAoZMa+ND+t246Okaw4Nq7p0hgg+KX2zN1FvI8MlGXtG9784K6m1Z44cjMtN463naY+kYTzLapRKukp7MEOjmr/+4L65uFzIaGLNAo1xcUGeUzqrST+Y6/9VF1+s6n7u7e+Iy48+/BA6waZp7oRu+nt3TvkTJ5lk9Gpn/18AfNk5lwawF8BvYFUquNU5dx2AFwFce1IjCQgIOK3oabF77x8CcMU6Ve9Y528BAQFnIfrqQVetVrF3714AwJVXXqnqZmdm1jsFgBZ7IvLiatQseQUFzBiRh00hx7z4AKBS0wQVCfLwqpsgE+XIRgdVI36WazKO6XlDLkFdbihpkdNFZB4k017WeJ0pFSWhReuITT7Eme5NBla+lYS5T5BoXV4iUoejxsxHG67ptK5rEZ9cogufHntLlst6rtjcxmJ3y+t75hRPW3eep+rm5sUk2KR3Ytyksjq8T9JBnbdLE1SkSe1bMDx8TFIxNNRbiidrluPjbp52J2u+C77xAQEDgrDYAwIGBGGxBwQMCPqqs7O77K233qrqlBpqdJokmZcylGLZG9LKOul4lkiSdSvWi6pVrbMrvnYbfcekFPQ72TBECE2a1kpNj/GlaTE9LZvorR0TEkuUKsq+QsMQa6bIxGjJCpjjnE2FKzqkDrUC6fMZS7Ahc1Kek/xltZp2ioqIcESRM0CTQfBGRaui3WqrRJhZL+v+05S6u0iEEkv6kSE/LK6/z794QNUdnZY9hyFybV02hKSbNomL8JVveJ2q4/n+9re/rere+973SjtyyeYyADTp3eyVSNLq6Cdrlgtf9oCAAUFY7AEBAwJ3KqJxer6Yc0ew6oCzAcDR4zQ/3TgbxgCEcViEcWic6DjO8d5PrFfR18UeX9S5B7z36znpDNQYwjjCOPo5jiDGBwQMCMJiDwgYEJypxX7TGbou42wYAxDGYRHGoXHKxnFGdPaAgID+I4jxAQEDgr4udufc1c65p5xzzzrn+sZG65z7gnNuyjm3h/7Wdyps59x259zdzrnHnXOPOec+cibG4pzLOufuc8493B7H77f/vss5d2/7+Xy1zV9w2uGci9r8hnecqXE4515wzj3qnHvIOfdA+29n4h05bbTtfVvsbjVx138C8AsALgbwfufcxd3POmW4GcDV5m9nggq7AeBfee8vBvAGAL/dnoN+j6UK4O3e+0sBXAbgaufcGwD8AYA/8t6fB2AWwHWneRzH8BGs0pMfw5kax9u895eRqetMvCOnj7bde9+XfwCuBPBtOv44gI/38fo7Aeyh46cAbG6XNwN4ql9joTHcBuCdZ3IsAPIAfgzg9Vh13kiu97xO4/W3tV/gtwO4A6uh9mdiHC8A2GD+1tfnAmAEwPNo76Wd6nH0U4zfCmAfHe9v/+1M4YxSYTvndgK4HMC9Z2IsbdH5IawShd4J4DkAc977YxEy/Xo+NwL415Awo/EzNA4P4DvOuQedc9e3/9bv53JaadvDBh26U2GfDjjnigD+EsDveO8V9Um/xuK9b3rvL8Pql/V1AC483de0cM5dA2DKe/9gv6+9Dt7kvX8NVtXM33bOvYUr+/RcToq2/Xjo52I/AGA7HW9r/+1MoScq7FMN51wKqwv9y977r5/JsQCA934OwN1YFZdLzsXxxP14PlcB+GXn3AsAvoJVUf6Pz8A44L0/0P5/CsBfYfUHsN/P5aRo24+Hfi72+wGc395pTQN4H4Db+3h9i9uxSoEN9EiFfbJwq0HHnwfwhPf+M2dqLM65CedcqV3OYXXf4AmsLvpjAdqnfRze+49777d573di9X34W+/9B/o9DudcwTk3dKwM4F0A9qDPz8V7fwjAPufcBe0/HaNtPzXjON0bH2aj4d0Ansaqfvh/9PG6fw7gIIA6Vn89r8OqbngXgGcAfBfAWB/G8SasimCPAHio/e/d/R4LgEsA/KQ9jj0A/m3777sB3AfgWQBfA5Dp4zN6K4A7zsQ42td7uP3vsWPv5hl6Ry4D8ED72XwDwOipGkfwoAsIGBCEDbqAgAFBWOwBAQOCsNgDAgYEYbEHBAwIwmIPCBgQhMUeEDAgCIs9IGBAEBZ7QMCA4P8HAtD7WqUXESgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loading dataset\n",
    "def get_attributes(filename):\n",
    "  f = open(filename, 'r')\n",
    "  lines = f.readlines()\n",
    "  attributes = []\n",
    "  i = 0\n",
    "  for line in lines:\n",
    "      if i != 0 and i != 1:\n",
    "        line = line.split()\n",
    "        #line.pop(0)\n",
    "        attributes.append(line)\n",
    "      i += 1\n",
    "  return attributes\n",
    "\n",
    "def initialize_training_set(): \n",
    "    all_attributes = get_attributes(PATH + ATTRIBUTES)\n",
    "    \n",
    "    while True:\n",
    "        chosen_info = random.sample(all_attributes, N)\n",
    "        chosen_attributes = [info[1:] for info in chosen_info]\n",
    "        chosen_images = [info[0] for info in chosen_info]\n",
    "        resized_images = []\n",
    "    \n",
    "        for ind in range(len(chosen_info)):\n",
    "            image_path = PATH + IMAGES + chosen_images[ind]\n",
    "            #img = cv2.imread(np.frombuffer(image_path), cv2.IMREAD_COLOR)#[...,::-1] / 255.0\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_COLOR)#[...,::-1] / 255.0\n",
    "            #img = img[45:173 , 25:153]\n",
    "            img = img[45:173,25:153]\n",
    "            img = cv2.resize(src=img, dsize=(64, 64))\n",
    "            #img = Image.open(image_path).crop(CROP_IMAGE_DIMS)\n",
    "            #img = img.resize((NEW_IMAGE_DIMS[0], NEW_IMAGE_DIMS[1]))\n",
    "            #img = cv2.resize(src=img, dsize=[NEW_IMAGE_DIMS[0], NEW_IMAGE_DIMS[0]])\n",
    "\n",
    "            #image = cv2.imdecode(np.frombuffer(image_path, np.uint8), cv2.IMREAD_COLOR)[...,::-1] / 255.0\n",
    "            #image = image[45:173 , 25:153]\n",
    "            #image = cv2.resize(src=image, dsize=(Image_Dim_Crop[0], Image_Dim_Crop[1]))\n",
    "            #resized_images += [img]\n",
    "            resized_images.append(img)\n",
    "            #np.append(resized_images, img)\n",
    "\n",
    "            \"\"\"\n",
    "            for name in chosen_images:\n",
    "                img = np.array((Image.open(PATH + IMAGES + name).crop(CROP_IMAGE_DIMS)).resize((NEW_IMAGE_DIMS[0], NEW_IMAGE_DIMS[1])))\n",
    "                resized_images.append(img)\n",
    "            resized_images = np.array(resized_images)\n",
    "            resized_images = np.array([imgs.astype('float32') for imgs in resized_images])\n",
    "            \"\"\"\n",
    "        resized_images = np.array(resized_images, dtype=np.float32)\n",
    "        chosen_attributes = np.array(chosen_attributes, dtype=np.float32)\n",
    "\n",
    "        yield [resized_images, chosen_attributes], None \n",
    "        \n",
    "def initialize_test_set():\n",
    "    all_attributes = get_attributes(PATH + ATTRIBUTES)\n",
    "    info_in_batches = []\n",
    "    attributes_in_batches = []\n",
    "    images_in_batches = []\n",
    "    test_set = []\n",
    "    \n",
    "    for i in range(NUM_BATCHES):\n",
    "        chosen_info = random.sample(all_attributes, BATCH_SIZE)\n",
    "        chosen_attributes = [info[1:] for info in chosen_info]\n",
    "        chosen_images = [info[0] for info in chosen_info]\n",
    "        \n",
    "        info_in_batches.append(chosen_info)\n",
    "        attributes_in_batches.append(chosen_attributes)\n",
    "        images_in_batches.append(chosen_images)\n",
    "        \n",
    "    for i in range(NUM_BATCHES):\n",
    "        chosen_images = images_in_batches[i]\n",
    "        attributes = attributes_in_batches[i]\n",
    "        resized_images = []\n",
    "        \n",
    "        for j in range(BATCH_SIZE):\n",
    "            image_path = PATH + IMAGES + chosen_images[j]\n",
    "            #img = cv2.imread(image_path, cv2.IMREAD_COLOR)[...,::-1] / 255.0\n",
    "            img = cv2.imread(image_path, cv2.IMREAD_COLOR)[...,::-1] / 255.0\n",
    "            #print(img)\n",
    "            img = img[45:173,25:153]\n",
    "            img = cv2.resize(src=img, dsize=(64, 64))\n",
    "            #np.append(resized_images, img)\n",
    "            resized_images.append(img)\n",
    "\n",
    "        resized_images = np.array(resized_images, dtype=np.float32)\n",
    "        #print(resized_images)\n",
    "        attributes = np.array(chosen_attributes, dtype=np.float32)\n",
    "\n",
    "        #yield [resized_images, attributes], None\n",
    "        test_set.append([resized_images, attributes])\n",
    "    return test_set, resized_images\n",
    "\n",
    "training_set = initialize_training_set()\n",
    "test_set, resized_images = initialize_test_set()\n",
    "#print(training_set)\n",
    "#print(test_set)\n",
    "\n",
    "plt.imshow(resized_images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "attribute_folder = PATH + ATTRIBUTES\n",
    "\n",
    "def celeba_generator():\n",
    "  read_attributes = pd.read_csv(attribute_folder, skiprows=2,header=None,delim_whitespace=True)\n",
    "  #attributes = np.array(pd.read_csv(Library + Attributes_txt_file, skiprows=2, header=None, delim_whitespace=True))\n",
    "  attribute_array = np.array(read_attributes)\n",
    "  with ZipFile(Celeba_Folder, 'r') as Celeba_Dataset: #Dundrer gjennom bildene i Celeba\n",
    "    while True: #Trekker ut random bilder fra 1D attributt array innenfor batch sizen\n",
    "      images = attribute_array[np.random.choice(attribute_array.shape[0], Batch_Size, replace=False)] #random.choice generates a random sample from 1D array\n",
    "      image_batch = []\n",
    "      attributes_batch = []\n",
    "      for image_info in images: #Litt usikker på hva som skjer her?\n",
    "        image = cv2.imdecode(np.frombuffer(Celeba_Dataset.read(Celeba_images + image_info[0]), np.uint8), cv2.IMREAD_COLOR)[...,::-1] / 255.0\n",
    "        image = image[45:173 , 25:153]\n",
    "        image = cv2.resize(src=image, dsize=(Image_Dim_Crop[0], Image_Dim_Crop[1]))\n",
    "        image_batch += [image]\n",
    "        attributes_batch += [image_info[1:]]\n",
    "      image_batch = np.array(image_batch, dtype=np.float32)\n",
    "      attribute_batch = np.array(attributes_batch, dtype=np.int32)\n",
    "\n",
    "      yield [image_batch, attribute_batch], None\n",
    "\n",
    "training_set = celeba_generator()\n",
    "\n",
    "print(training_set)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 32, 32, 32)   896         input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 16, 16, 64)   18496       conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 8, 8, 128)    73856       conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 4, 4, 256)    295168      conv2d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 2, 2, 512)    1180160     conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_55 (Flatten)            (None, 2048)         0           conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 64)           131136      flatten_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_log_sigma (Dense)             (None, 64)           131136      flatten_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sampling_19 (Sampling)          [(None, 64), (None,  0           z_mean[0][0]                     \n",
      "                                                                 z_log_sigma[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "labels (InputLayer)             (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 104)          0           sampling_19[0][0]                \n",
      "                                                                 labels[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,830,848\n",
      "Trainable params: 1,830,848\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 104)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2048)              215040    \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_91 (Conv2DT (None, 4, 4, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_92 (Conv2DT (None, 8, 8, 128)         295040    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_93 (Conv2DT (None, 16, 16, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_94 (Conv2DT (None, 32, 32, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_95 (Conv2DT (None, 64, 64, 3)         867       \n",
      "=================================================================\n",
      "Total params: 1,783,107\n",
      "Trainable params: 1,783,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Sampling(Layer):\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def VAE():\n",
    "  #Define encoder model.\n",
    "  input_img = Input(shape = NEW_IMAGE_DIMS, name='input_img')\n",
    "  labels = Input(shape = (NUM_ATTRIBUTES,), name='labels')\n",
    "\n",
    "  x = Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same', activation = 'relu')(input_img)\n",
    "  x = Conv2D(filters = 64, kernel_size = 3, strides = 2, padding = 'same', activation = 'relu')(x)\n",
    "  x = Conv2D(filters = 128, kernel_size = 3, strides = 2, padding = 'same', activation = 'relu')(x)\n",
    "  x = Conv2D(filters = 256, kernel_size = 3, strides = 2, padding = 'same', activation = 'relu')(x)\n",
    "  x = Conv2D(filters = 512, kernel_size = 3, strides = 2, padding = 'same', activation = 'relu')(x)\n",
    "\n",
    "  #encode = Encode_Decode(input_img) #Done\n",
    "\n",
    "  shape_before_flattening = K.int_shape(x)[1:]\n",
    "  #shape_before_flattening = K.int_shape(encode)[1:]\n",
    "\n",
    "  x = Flatten()(x)\n",
    "\n",
    "  z_mean = Dense(LATENT_DIM, name='z_mean')(x)\n",
    "  z_log_sigma = Dense(LATENT_DIM, name='z_log_sigma')(x)\n",
    "  z = Sampling()([z_mean, z_log_sigma])\n",
    "\n",
    "  zy = Concatenate()([z, labels])\n",
    "\n",
    "  inputs_embedding = Input(shape=(LATENT_DIM + NUM_ATTRIBUTES,))\n",
    "  embedding = Dense(np.prod(shape_before_flattening))(inputs_embedding)\n",
    "  embedding = Reshape(shape_before_flattening)(embedding)\n",
    "\n",
    "  #Decoding\n",
    "  x_ = Conv2DTranspose(filters = 256, kernel_size = 3, strides = 2,  padding = 'same', activation = 'relu')(embedding)\n",
    "  x_ = Conv2DTranspose(filters = 128, kernel_size = 3, strides = 2,  padding = 'same', activation = 'relu')(x_)\n",
    "  x_ = Conv2DTranspose(filters = 64, kernel_size = 3, strides = 2,  padding = 'same', activation = 'relu')(x_)\n",
    "  x_ = Conv2DTranspose(filters = 32, kernel_size = 3, strides = 2,  padding = 'same', activation = 'relu')(x_)\n",
    "  x_ = Conv2DTranspose(filters = 3, kernel_size = 3, strides = 2,  padding = 'same', activation = 'sigmoid')(x_)\n",
    "\n",
    "  #x_hat = Encode_Decode(embedding)\n",
    "\n",
    "  encoder = Model(inputs = [input_img, labels], outputs = zy, name=\"encoder\")\n",
    "  decoder = Model(inputs = inputs_embedding, outputs = x_, name=\"decoder\")\n",
    "\n",
    "  vae_out = decoder(encoder([input_img, labels]))\n",
    "\n",
    "  rec_loss =  np.prod(NEW_IMAGE_DIMS) * binary_crossentropy(Flatten()(input_img), Flatten()(vae_out))\n",
    "  kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "  vae_loss = K.mean(rec_loss + kl_loss)\n",
    "\n",
    "  vae = Model(inputs = [input_img, labels], outputs = vae_out, name=\"vae\")\n",
    "\n",
    "  vae.add_loss(vae_loss)\n",
    "\n",
    "  optimizer = Adam(lr=0.0005, beta_1 = 0.5)\n",
    "  vae.compile(optimizer)\n",
    "\n",
    "  return vae, encoder, decoder\n",
    "\n",
    "vae, encoder, decoder = VAE()\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1582/1582 [==============================] - 360s 228ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14c6e1790>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit(training_set, steps_per_epoch=TOT_IMAGES//BATCH_SIZE, verbose=1, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "vae.save_weights('./vae.h5')\n",
    "decoder.save_weights('./decoder.h5')\n",
    "encoder.save_weights('./encoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# load cifar10 images\\n(images1, _), (images2, _) = cifar10.load_data()\\nshuffle(images1)\\nimages1 = images1[:10000]\\nprint('Loaded', images1.shape, images2.shape)\\n\\n# convert integer to floating point values\\nimages1 = images1.astype('float32')\\nimages2 = images2.astype('float32')\\n\\n# resize images\\nimages1 = scale_images(images1, (299,299,3))\\nimages2 = scale_images(images2, (299,299,3))\\nprint('Scaled', images1.shape, images2.shape)\\n# pre-process images\\nimages1 = preprocess_input(images1)\\nimages2 = preprocess_input(images2)\\n# calculate fid\\nfid = calculate_fid(model, images1, images2)\\nprint('FID: %.3f' % fid)\\n\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Frechet Inception Distance (https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/)\n",
    "\n",
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)\n",
    "\n",
    "# calculate frechet inception distance\n",
    "def calculate_fid(model, images1, images2):\n",
    "    # calculate activations\n",
    "    act1 = model.predict(images1)\n",
    "    act2 = model.predict(images2)\n",
    "    # calculate mean and covariance statistics\n",
    "    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
    "    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
    "    # calculate sum squared difference between means\n",
    "    ssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
    "    # calculate sqrt of product between cov\n",
    "    covmean = sqrtm(sigma1.dot(sigma2))\n",
    "    # check and correct imaginary numbers from sqrt\n",
    "    if iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    # calculate score\n",
    "    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
    "    return fid\n",
    "\n",
    "# prepare the inception v3 model\n",
    "model = InceptionV3(include_top=False, pooling='avg')#, input_shape=(299,299,3))\n",
    "\"\"\"\n",
    "# load cifar10 images\n",
    "(images1, _), (images2, _) = cifar10.load_data()\n",
    "shuffle(images1)\n",
    "images1 = images1[:10000]\n",
    "print('Loaded', images1.shape, images2.shape)\n",
    "\n",
    "# convert integer to floating point values\n",
    "images1 = images1.astype('float32')\n",
    "images2 = images2.astype('float32')\n",
    "\n",
    "# resize images\n",
    "images1 = scale_images(images1, (299,299,3))\n",
    "images2 = scale_images(images2, (299,299,3))\n",
    "print('Scaled', images1.shape, images2.shape)\n",
    "# pre-process images\n",
    "images1 = preprocess_input(images1)\n",
    "images2 = preprocess_input(images2)\n",
    "# calculate fid\n",
    "fid = calculate_fid(model, images1, images2)\n",
    "print('FID: %.3f' % fid)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_dataset():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object celeba_vae_eval_generator at 0x1467fc6d0>\n",
      "<generator object initialize_test_set at 0x14733ccd0>\n"
     ]
    }
   ],
   "source": [
    "def celeba_vae_eval_generator():\n",
    "  attributes = np.array(pd.read_csv(Library + Attributes_txt_file, skiprows=2, header=None, delim_whitespace=True))\n",
    "  attributes = attributes[np.random.choice(attributes.shape[0], 10000, replace=False)]\n",
    "  with ZipFile(Library + Celeba_Zip, 'r') as Celeba_Dataset:\n",
    "    batched = 0\n",
    "    while batched < 10000:\n",
    "      images = attributes[batched: batched + Batch_Size]\n",
    "      image_batch = []\n",
    "      attributes_batch = []\n",
    "      for image_info in images:\n",
    "        image = cv2.imdecode(np.frombuffer(Celeba_Dataset.read(Celeba_images + image_info[0]), np.uint8), cv2.IMREAD_COLOR)[...,::-1] / 255.0\n",
    "        image = image [45:173 , 25:153]\n",
    "        image = cv2.resize(src=image, dsize=(Image_Dim_Crop[0], Image_Dim_Crop[1]))\n",
    "        image_batch += [image]\n",
    "        attributes_batch += [image_info[1:]]\n",
    "      image_batch = np.array(image_batch, dtype=np.float32)\n",
    "      attribute_batch = np.array(attributes_batch, dtype=np.int32)\n",
    "\n",
    "      batched += Batch_Size\n",
    "\n",
    "      yield [image_batch, attribute_batch]\n",
    "\n",
    "validation_dataset = celeba_vae_eval_generator()\n",
    "print(validation_dataset)\n",
    "validation_dataset = test_set\n",
    "\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating activations for each batch...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'show_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-60fc8d0885d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show_batch' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Calculating activations for each batch...\")\n",
    "img_act = np.array([]).reshape((0, 2048))\n",
    "pred_act = np.array([]).reshape((0, 2048))\n",
    "i = 1\n",
    "for batch in validation_dataset:\n",
    "  images = batch[0]\n",
    "  print(\"Batch\", i, \"- Num. samples:\", images.shape[0])\n",
    "  predictions = vae.predict(batch)\n",
    "  if i == 1:\n",
    "    imgs1 = images\n",
    "    prediction1 = predictions\n",
    "  images = images * 255.0\n",
    "  predictions = predictions * 255.0\n",
    "  images1 = scale_images(images, (299, 299, 3))\n",
    "  images1 = preprocess_input(images1)\n",
    "  images2 = scale_images(predictions, (299, 299, 3))\n",
    "  images2 = preprocess_input(images2)\n",
    "  a = inception_model.predict(images1)\n",
    "  b = inception_model.predict(images2)\n",
    "  img_act = np.concatenate((img_act, a), axis = 0)\n",
    "  pred_act = np.concatenate((pred_act, b), axis = 0)\n",
    "  i += 1\n",
    "print(\"Done!\")\n",
    "show_batch(imgs1)\n",
    "show_batch(prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
